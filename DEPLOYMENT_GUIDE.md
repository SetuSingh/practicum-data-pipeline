# ğŸš€ Deployment Guide - Cross-Platform Setup

## ğŸ“‹ **SYSTEM REQUIREMENTS**

### **Minimum Requirements:**

- **OS**: macOS 10.15+, Windows 10+, Ubuntu 18.04+
- **RAM**: 8GB minimum, 16GB recommended
- **CPU**: 4 cores minimum, 8 cores recommended
- **Storage**: 10GB free space
- **Docker**: Docker Desktop 4.0+ with Docker Compose
- **Python**: Python 3.9+ (3.11+ recommended)
- **Java**: Java 11+ (Java 17+ recommended for best Spark compatibility)

---

## ğŸ”§ **ONE-COMMAND SETUP**

### **Quick Start (Recommended)**

```bash
# Clone and setup everything automatically
git clone <repository-url>
cd practicum
chmod +x start-setup.sh
./start-setup.sh
```

This script handles:

- âœ… Docker service startup
- âœ… Python environment creation
- âœ… Dependency installation
- âœ… Database schema setup
- âœ… Kafka topic creation
- âœ… Test data generation

---

## ğŸ“¦ **MANUAL SETUP (If Automated Setup Fails)**

### **Step 1: Prerequisites**

```bash
# Verify Docker is running
docker --version && docker-compose --version

# Verify Python version
python3 --version  # Should be 3.9+

# Verify Java (for Spark)
java -version  # Should be Java 11+
```

### **Step 2: Infrastructure**

```bash
# Start all services in Docker
docker-compose up -d

# Wait for services to be ready (30-60 seconds)
docker-compose ps  # All services should show "Up"
```

### **Step 3: Python Environment**

```bash
# Navigate to backend
cd backend

# Create virtual environment
python3 -m venv venv

# Activate environment
source venv/bin/activate  # macOS/Linux
# OR
venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt
```

### **Step 4: Database Setup**

```bash
# Setup PostgreSQL database and schema
python setup/setup_database.py

# Verify database connection
python -c "
from src.database.postgres_connector import PostgreSQLConnector
db = PostgreSQLConnector('localhost', 5433, 'compliance_db', 'admin', 'password')
print('âœ… Database connected successfully')
"
```

### **Step 5: Kafka Setup**

```bash
# Create Kafka topics
docker exec practicum-kafka kafka-topics \
  --create --topic healthcare-stream \
  --bootstrap-server localhost:9092 \
  --partitions 3 --replication-factor 1

# Verify Kafka connectivity
python -c "
from kafka import KafkaProducer
producer = KafkaProducer(bootstrap_servers=['localhost:9093'])
producer.close()
print('âœ… Kafka connected successfully')
"
```

### **Step 6: Test System**

```bash
# Run comprehensive system test
python test_real_vs_simulated_fixed.py

# Should show all âœ… REAL processing modes working
```

---

## ğŸŒ **CROSS-PLATFORM COMPATIBILITY**

### **macOS (Intel & Apple Silicon)**

```bash
# For Apple Silicon Macs, ensure Docker uses correct architecture
export DOCKER_DEFAULT_PLATFORM=linux/amd64

# Run setup
./start-setup.sh
```

### **Windows**

```powershell
# Use PowerShell or Git Bash
# Ensure Docker Desktop is running with WSL2 backend

# Clone repository
git clone <repository-url>
cd practicum

# Run setup (use Git Bash)
bash start-setup.sh
```

### **Linux (Ubuntu/Debian)**

```bash
# Install Docker if not present
sudo apt update
sudo apt install docker.io docker-compose

# Add user to docker group
sudo usermod -aG docker $USER
newgrp docker

# Run setup
./start-setup.sh
```

---

## ğŸ”§ **CONFIGURATION FILES**

### **Docker Services (`docker-compose.yml`)**

- âœ… **Kafka**: Port 9093 (external)
- âœ… **PostgreSQL**: Port 5433 (external)
- âœ… **Spark Master**: Port 8080 (UI)
- âœ… **Flink Dashboard**: Port 8082 (UI)
- âœ… **Storm UI**: Port 8084 (UI)
- âœ… **Grafana**: Port 3000 (admin/admin)

### **Python Dependencies (`backend/requirements.txt`)**

- âœ… **Core**: pandas, numpy, pyspark
- âœ… **Messaging**: kafka-python
- âœ… **Database**: psycopg2-binary
- âœ… **Web**: Flask, Flask-CORS
- âœ… **Utilities**: requests, setuptools

### **Frontend (`frontend/package.json`)**

- âœ… **Framework**: React 18 with TypeScript
- âœ… **Build**: Vite with hot reload
- âœ… **UI**: Tailwind CSS, Lucide icons
- âœ… **Charts**: Recharts for visualization

---

## ğŸš¨ **TROUBLESHOOTING**

### **Common Issues & Solutions**

#### **1. Spark Java Compatibility Error**

```
Error: "getSubject is supported only if a security manager is allowed"
```

**Solution**: Java security flags are already configured in `SparkBatchProcessor`:

```python
.config("spark.driver.extraJavaOptions", "-Djava.security.manager=allow")
.config("spark.executor.extraJavaOptions", "-Djava.security.manager=allow")
```

#### **2. Kafka Connection Refused**

```
Error: "[Errno 61] Connection refused"
```

**Solutions**:

```bash
# Check Docker services
docker-compose ps

# Restart Kafka
docker-compose restart kafka

# Wait 30 seconds and test
python -c "from kafka import KafkaProducer; KafkaProducer(bootstrap_servers=['localhost:9093'])"
```

#### **3. PostgreSQL Connection Failed**

```
Error: "could not connect to server"
```

**Solutions**:

```bash
# Check PostgreSQL container
docker logs practicum-postgres

# Restart PostgreSQL
docker-compose restart postgres

# Verify port is available
netstat -an | grep 5433
```

#### **4. Docker Platform Issues (Apple Silicon)**

```
Error: Platform compatibility warnings
```

**Solution**:

```bash
export DOCKER_DEFAULT_PLATFORM=linux/amd64
docker-compose up -d
```

#### **5. Python Package Conflicts**

```
Error: Version conflicts or import errors
```

**Solution**:

```bash
# Fresh virtual environment
rm -rf venv
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

## ğŸ“Š **VERIFICATION COMMANDS**

### **Infrastructure Check**

```bash
# Docker services status
docker-compose ps

# Should show all services as "Up":
# - practicum-kafka
# - practicum-postgres
# - practicum-zookeeper
# - practicum-spark-master
# - practicum-flink-jobmanager
```

### **Application Check**

```bash
# Backend test
cd backend
python test_real_vs_simulated_fixed.py

# Expected output:
# âœ… Kafka: Available
# âœ… Spark Batch Engine: Distributed processing ready
# âœ… Storm Stream Engine: Kafka integration ready
# âœ… Flink Hybrid Engine: Intelligent routing ready
```

### **Frontend Check**

```bash
# Frontend development server
cd frontend
npm install
npm run dev

# Should open http://localhost:3007
```

---

## ğŸŒ **NETWORK PORTS**

| Service         | Internal Port | External Port | Purpose               |
| --------------- | ------------- | ------------- | --------------------- |
| Kafka           | 29092         | 9093          | Message streaming     |
| PostgreSQL      | 5432          | 5433          | Compliance database   |
| Zookeeper       | 2181          | 2182          | Kafka coordination    |
| Spark Master    | 8080          | 8080          | Spark cluster UI      |
| Flink Dashboard | 8081          | 8082          | Flink job monitoring  |
| Storm UI        | 8080          | 8084          | Storm topology UI     |
| Grafana         | 3000          | 3000          | Monitoring dashboards |
| Flask Backend   | 5000          | 5000          | API server            |
| React Frontend  | 3007          | 3007          | Web interface         |

---

## ğŸ“‚ **PROJECT STRUCTURE**

```
practicum/
â”œâ”€â”€ ğŸ³ docker-compose.yml      # All infrastructure services
â”œâ”€â”€ ğŸš€ start-setup.sh          # One-command setup script
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ ğŸ“¦ requirements.txt    # Python dependencies
â”‚   â”œâ”€â”€ ğŸŒ app.py              # Flask application
â”‚   â”œâ”€â”€ ğŸ”§ src/               # Processing engines
â”‚   â”œâ”€â”€ ğŸ“Š data/              # Input/output data
â”‚   â””â”€â”€ ğŸ§ª tests/             # Test suites
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ ğŸ“¦ package.json       # Node.js dependencies
â”‚   â”œâ”€â”€ âš›ï¸ src/               # React components
â”‚   â””â”€â”€ ğŸ¨ public/            # Static assets
â””â”€â”€ setup/
    â”œâ”€â”€ ğŸ—„ï¸ setup_database.py   # Database initialization
    â””â”€â”€ âš¡ quick_start.sh      # Alternative setup script
```

---

## âœ… **SUCCESS INDICATORS**

### **System Ready When You See:**

```bash
âœ… Docker services: All containers running
âœ… Kafka: 10+ topics available
âœ… PostgreSQL: 6+ users in compliance database
âœ… Spark: Distributed processing engine ready
âœ… Frontend: Development server on http://localhost:3007
âœ… Backend: API server on http://localhost:5000
```

### **Test Processing:**

```bash
# Upload a CSV file through the web interface
# OR use direct API:
curl -X POST http://localhost:5000/api/upload \
  -F "file=@your_data.csv" \
  -F "pipeline=batch"

# Should return job_id and start processing immediately
```

---

## ğŸ¯ **DEPLOYMENT SUMMARY**

Your data processing pipeline is designed for **maximum portability**:

- âœ… **Docker Containerization**: All infrastructure services
- âœ… **Python Virtual Environment**: Isolated dependencies
- âœ… **Cross-platform Support**: macOS, Windows, Linux
- âœ… **Automated Setup**: One-command deployment
- âœ… **Zero Configuration**: Works out of the box
- âœ… **Real Infrastructure**: No simulations or mocks

**Expected Setup Time**: 5-10 minutes for full deployment

ğŸš€ **Your system is enterprise-ready and fully portable!**
